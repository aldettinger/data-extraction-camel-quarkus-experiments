quarkus.langchain4j.ollama.timeout = 3m

quarkus.langchain4j.ollama.chat-model.model-id = codellama
quarkus.langchain4j.ollama.chat-model.format = json

quarkus.langchain4j.ollama.chat-model.temperature = 0

# Uncomment to log HTTP traffic between langchain4j & the LLM API
quarkus.rest-client.logging.scope=request-response
quarkus.rest-client.logging.body-limit=10000
quarkus.log.category."org.jboss.resteasy.reactive.client.logging".level=DEBUG
